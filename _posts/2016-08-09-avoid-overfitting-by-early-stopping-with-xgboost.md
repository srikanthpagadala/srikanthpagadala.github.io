---
layout: post
title: "Avoid Overfitting by Early Stopping with XGBoost"
date: 2016-08-09
categories: ['Machine Learning']
---

Overfitting is a problem with sophisticated non-linear learning algorithms like gradient boosting.

Here you will discover how you can use early stopping to limit overfitting with XGBoost in Python.

By the end you will know:

- About early stopping as an approach to reducing overfitting of training data?
- How to monitor the performance of an XGBoost model during training and plot the learning curve?
- How to use early stopping to prematurely stop the training of an XGBoost model at an optimal epoch?

[Source Code](https://github.com/srikanthpagadala/machine-learning-projects/tree/master/Avoid%20Overfitting%20by%20Early%20Stopping%20With%20XGBoost){:target="_blank"}

[Report](http://htmlpreview.github.io/?https://github.com/srikanthpagadala/machine-learning-projects/blob/master/Avoid%20Overfitting%20by%20Early%20Stopping%20With%20XGBoost/report.html){:target="_blank"}

Next: [Tune Multithreading Support for XGBoost](/notes/2016/08/10/tune-multithreading-support-for-xgboost)

