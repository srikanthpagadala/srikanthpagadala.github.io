---
layout: post
title: "Evaluate Gradient Boosting Models with XGBoost"
date: 2016-08-06
categories: ['Machine Learning']
---

The goal of developing a predictive model is to develop a model that is accurate on unseen data.

This can be achieved using statistical techniques where the training dataset is carefully used to estimate the performance of the model on new and unseen data.

Here you will discover how you can evaluate the performance of your gradient boosting models with XGBoost in Python.

By the end you will know.

- How to evaluate the performance of your XGBoost models using train and test datasets?
- How to evaluate the performance of your XGBoost models using k-fold cross validation?

[Source Code](https://github.com/srikanthpagadala/machine-learning-projects/tree/master/Evaluate%20Gradient%20Boosting%20Models%20with%20XGBoost){:target="_blank"}

[Report](http://htmlpreview.github.io/?https://github.com/srikanthpagadala/machine-learning-projects/blob/master/Evaluate%20Gradient%20Boosting%20Models%20with%20XGBoost/report.html){:target="_blank"}

Next: [Visualize Gradient Boosting Decision Trees With XGBoost](/notes/2016/08/07/visualize-gradient-boosting-decision-trees-with-xgboost)

